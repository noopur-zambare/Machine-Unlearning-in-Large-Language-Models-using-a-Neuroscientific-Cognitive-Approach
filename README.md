# Machine-Unlearning-in-Large-Language-Models-using-a-Neuroscientific-Cognitive-Approach

Our brains are remarkable devices that can learn new things, but what happens when we have to let go of knowledge that is out of date or inaccurate? In the human brain, unlearning is a complicated process with many steps that involve a fascinating balance of neurons and memories.


### Brain & Unlearning
- Recognizing the Glitch: The brain's competing messages are the first step in this. Consider the firing of two neurons, each of which represents a distinct memory. They clash, sending up a warning flag, an inside "huh?" Emotions also have an impact. The brain marks something for further examination if it feels odd. Unlearning can be triggered even by external feedback.
  
- Weakening the Connections: To create a flexible and dynamic information network, the brain uses techniques to weaken connections in Step 2 of the cognitive process. Synaptic pruning can be thought of as a kind of metaphorical gardening where neurons weaken connections that have not been used, like weeds growing over a path that has not been walked. The brain's cognitive pathways are streamlined by this natural process, which enables the brain to discard theÂ unnecessary information. "Reconsolidation window" theory is compared to a newly poured concrete sidewalk; it is initially pliable and soft, allowing for easy reshaping. But with time, it gets harder and less amenable to reform. The brain can change previous connections within this window of memory malleability, which guarantees that our cognitive landscape will always be evolving. Furthermore, emotional dampeners function as cognitive dimmer switches, enabling the brain to reduce the strength of emotionally connected memories. A more objective reevaluation of the data is made possible by this process, which permits a sophisticated and flexible cognitive response.
  
- Integrating New Knowledge: Our brains actively engage with new information in the dynamic cognitive process of "active learning," making an effort to reconcile it with what we already know. This entails complex modifications, such as enhancing some neuronal connections, attenuating others, and sometimes creating completely new ones. The brain is excellent at finding patterns in incoming information, much like an advanced pattern recognition machine. New information fits into the pre-existing knowledge network when it is consistent with the patterns, which makes learning more effective. Moreover, the brain has built-in error repair mechanisms that are similar to self-editing mental proofreading. These integrated feedback loops continuously check for logical mistakes and inconsistencies. When they are detected, these systems trigger the adjustments that are required to keep our mental model accurate and continuously improved.


### Working of Neuroscientific-Cognitive Approach for Machine Unlearning
- Developed and improved a state-of-the-art unlearning algorithm for Large Language Models by adding extensive representations of the memory system, modulations of the attention mechanism, and other cognitive processes motivated by neuroscience.
- Created an adaptive threshold mechanism for the reconsolidation window to optimise unlearning timing and requirement depending on error severity, concept usage frequency, and emotional connotations.


### Algorithm
Markup :  1. Processing of Input: An input job or text is given to the LLM.
          2. Attention Allocation: Based on the input, the Attention Mechanism distributes resources across pertinent concepts in the Memory System.
          3. Output Generation: Using the information it has received and its internal thought processes, the LLM produces an output.
          4. Error Detection: The Error Detection Unit looks for internal discrepancies or compares the output with sources outside of the system.
          5. Reconsolidation Trigger: The Error Detection Unit notifies the Reconsolidation Window to open for concepts associated with the error if an error is found.
          6. Memory Update: Ideas that were previously inactive during the Reconsolidation Window are now reactivated and open to change.
          7. Feedback Integration: The Memory System and the Attention Mechanism receive information regarding the error and possible fixes from the Feedback Loop.
          8. Memory Modification: In response to feedback, the Memory System modifies representations of pertinent concepts, possibly erasing or weakening information associated with the error.
          9. Attention Bias Refinement: In response to changes in the Memory System, the Attention Mechanism modifies its focus, giving corrected information priority and downplaying previously contradictory concepts.
          10. Adaptive Learning: By iteratively strengthening the LLM's knowledge base and enhancing its capacity to unlearn inaccurate or out-of-date information, this process is carried on with subsequent inputs.

